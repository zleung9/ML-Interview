{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    # print(ch1, ch2)\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# plt.imshow(N, cmap='Blues')\n",
    "# for i in range(27):\n",
    "#     for j in range(27):\n",
    "#         chstr = itos[i] + itos[j]\n",
    "#         plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='black')\n",
    "#         plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='black')\n",
    "# plt.axis('off');\n",
    "# # plt.savefig(\"character_heatmap.png\", dpi=100, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next charactor probability\n",
    "For a given charactor (e.g. 'h'), what is the probability of next character (e.g.'a')?\n",
    "\n",
    "The calculation is essentially performing row-wise probility\n",
    "\n",
    "Note:\n",
    "1. use `keepdims` to keep the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1192e-05, 1.9583e-01, 4.3039e-02, 2.7536e-02, 9.3609e-02, 1.9482e-01,\n",
       "        8.6910e-02, 5.5783e-02, 3.1532e-01, 1.4046e-01, 2.4599e-02, 7.1837e-02,\n",
       "        9.4029e-02, 7.7523e-02, 3.6853e-01, 1.0752e-01, 3.2289e-02, 9.6990e-02,\n",
       "        1.0827e-01, 1.4386e-01, 8.6475e-02, 4.9336e-02, 3.4231e-02, 5.4393e-02,\n",
       "        2.2790e-01, 2.0484e-01, 6.6392e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visthlynnnn.\n",
      "draclalelaika.\n",
      "deelax.\n",
      "ka.\n",
      "ereien.\n",
      "derbinnonos.\n",
      "shycleria.\n",
      "lahamanabor.\n",
      "jentrwairtiti.\n",
      "ssha.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2025)\n",
    "for i in range(10):\n",
    "    out = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        p = P[idx]\n",
    "        idx = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[idx])\n",
    "        if idx == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: maximize the likelihood function: $$\\prod{P_{i{\\rightarrow}j}} = \\prod{W_{ij}}$$\n",
    "equivilent to minimizing the log likelihood: $$loss=-\\log{\\prod{W_{ij}}} = -\\sum{\\log{W_{ij}}}$$\n",
    "ATTENTION!!  \n",
    "Sum over `(i,j)` is over all possible `(i,j)` pairs in the **dataset**, in our case there are ~228k of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".e: 0.0478 -3.0410\n",
      "em: 0.0377 -3.2793\n",
      "mm: 0.0253 -3.6753\n",
      "ma: 0.3885 -0.9454\n",
      "a.: 0.1958 -1.6305\n",
      "\n",
      "Total number of possble pairs: 228146\n",
      "log_likelihood=tensor(-559951.5625)\n",
      "nll=tensor(559951.5625)\n",
      "2.4543561935424805\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words: # 2.4543\n",
    "# for w in [\"andrej\"]: # 3.0367\n",
    "# for w in [\"acexhlaahllhekhclalelaika\"]: # 3.2235\n",
    "# for w in [\"ihaiaxrkhherhieikaoaaikaokhyokhkclhriaalahoia\"]: # 3.6665\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    if n<=5:\n",
    "      print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "    \n",
    "\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(f\"\\nTotal number of possble pairs: {n:d}\")\n",
    "print(f'{log_likelihood=}')\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of bigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    print(ch1, ch2)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5143)\n"
     ]
    }
   ],
   "source": [
    "nll = 0\n",
    "for (x, y) in zip(xs, ys):\n",
    "    nll -= P[x, y].log()\n",
    "nll /= len(xs)\n",
    "print(nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized nll calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x132a075c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding is essentially **row retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8057],\n",
       "        [-0.1819],\n",
       "        [-0.9100],\n",
       "        [-0.9100],\n",
       "        [-0.1447]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5, 27) @ (27, 1) -> (5, 1)\n",
    "W = torch.randn((27, 1))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8057],\n",
       "        [-0.1819],\n",
       "        [-0.9100],\n",
       "        [-0.9100],\n",
       "        [-0.1447]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[xs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZATION single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1607, -1.5591,  0.7782, -0.9990, -0.3729, -0.1594,  0.2836, -1.1234,\n",
       "          0.9813, -1.7471, -0.2819,  0.1437,  1.6156,  0.1340,  0.2344,  1.3478,\n",
       "         -0.8244, -0.5120,  0.3246,  0.9116,  0.4670,  1.1802,  0.3709, -2.0193,\n",
       "         -1.7463,  1.7367, -0.0385],\n",
       "        [-0.1079, -1.1414,  0.3533, -0.0972, -0.1674, -0.8230,  1.5285,  0.5849,\n",
       "          0.2286,  1.3484,  0.3098, -1.3261, -1.1577, -0.5698, -0.2010, -1.5212,\n",
       "         -0.1028, -1.3112,  0.8517, -0.5402, -0.8619, -0.8897, -0.0430, -0.0234,\n",
       "          0.3451,  0.4353,  0.3396],\n",
       "        [-0.1216, -1.4042, -0.7816, -0.0619, -0.6913,  0.1283,  0.0171, -0.6039,\n",
       "         -0.2212, -0.6068,  0.9244,  1.5373,  0.9788,  0.3045,  0.2875, -0.5763,\n",
       "         -1.2434,  2.5755,  0.2263, -1.1001,  0.0859, -0.3946,  0.7082, -0.6777,\n",
       "         -1.0835,  1.0831, -1.7251],\n",
       "        [-0.3459,  1.9443,  2.9956,  0.4264, -0.6470,  0.9924, -0.7880,  0.8784,\n",
       "         -0.5795,  0.9157,  1.7834, -0.7768, -2.0405,  0.7085,  1.2933, -1.8107,\n",
       "         -0.6428,  0.7947,  0.4696,  0.1908, -0.5113,  0.7000,  0.6974, -1.1440,\n",
       "          0.6908, -2.1380, -1.9770],\n",
       "        [-0.0067, -0.3769,  0.4742,  0.4001, -1.1268, -0.4783, -2.5161, -0.0874,\n",
       "         -0.3265,  0.0139, -0.2752, -0.1947,  0.4738, -1.1182,  0.0978, -0.3508,\n",
       "          0.6439,  0.5409,  1.4766,  1.6015,  1.7138,  0.1901,  0.1718,  1.2371,\n",
       "         -0.2818, -0.4241,  1.0259]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5, 27) @ (27, 27) -> (5, 27)\n",
    "g = torch.Generator().manual_seed(2025)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "W[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use softmax to turn logits into probabilities\n",
    "$$p_i=\\frac{\\exp(x_i)}{\\sum{\\exp{x_i}}}$$\n",
    "$$\\sum{p_i}=1$$\n",
    "logits: $x_i$  \n",
    "counts: $\\exp{x_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0077, 0.0052, 0.0538, 0.0091, 0.0170, 0.0211, 0.0328, 0.0080, 0.0659,\n",
       "         0.0043, 0.0186, 0.0285, 0.1243, 0.0283, 0.0312, 0.0951, 0.0108, 0.0148,\n",
       "         0.0342, 0.0615, 0.0394, 0.0805, 0.0358, 0.0033, 0.0043, 0.1404, 0.0238],\n",
       "        [0.0288, 0.0103, 0.0458, 0.0292, 0.0272, 0.0141, 0.1482, 0.0577, 0.0404,\n",
       "         0.1237, 0.0438, 0.0085, 0.0101, 0.0182, 0.0263, 0.0070, 0.0290, 0.0087,\n",
       "         0.0753, 0.0187, 0.0136, 0.0132, 0.0308, 0.0314, 0.0454, 0.0497, 0.0451],\n",
       "        [0.0206, 0.0057, 0.0107, 0.0219, 0.0117, 0.0265, 0.0237, 0.0127, 0.0187,\n",
       "         0.0127, 0.0587, 0.1083, 0.0620, 0.0316, 0.0310, 0.0131, 0.0067, 0.3059,\n",
       "         0.0292, 0.0077, 0.0254, 0.0157, 0.0473, 0.0118, 0.0079, 0.0688, 0.0041],\n",
       "        [0.0111, 0.1101, 0.3150, 0.0241, 0.0082, 0.0425, 0.0072, 0.0379, 0.0088,\n",
       "         0.0394, 0.0937, 0.0072, 0.0020, 0.0320, 0.0574, 0.0026, 0.0083, 0.0349,\n",
       "         0.0252, 0.0191, 0.0094, 0.0317, 0.0316, 0.0050, 0.0314, 0.0019, 0.0022],\n",
       "        [0.0235, 0.0162, 0.0380, 0.0352, 0.0077, 0.0146, 0.0019, 0.0216, 0.0170,\n",
       "         0.0240, 0.0179, 0.0194, 0.0379, 0.0077, 0.0261, 0.0166, 0.0450, 0.0406,\n",
       "         0.1034, 0.1172, 0.1311, 0.0286, 0.0281, 0.0814, 0.0178, 0.0155, 0.0659]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = W.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4614, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = -probs[xs, ys].log().mean()\n",
    "print(loss) # Bigram: 2.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W.data -= 1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0340, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "counts = W.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[xs, ys].log().mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZATION loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.776524782180786\n",
      "2.5711255073547363\n",
      "2.5134506225585938\n",
      "2.4918532371520996\n",
      "2.4807255268096924\n",
      "2.4742610454559326\n",
      "2.470158815383911\n",
      "2.4673547744750977\n",
      "2.4653282165527344\n",
      "2.46380352973938\n",
      "2.4626243114471436\n",
      "2.4616918563842773\n",
      "2.460939407348633\n",
      "2.460320472717285\n",
      "2.4598021507263184\n",
      "2.459360361099243\n",
      "2.4589788913726807\n",
      "2.4586451053619385\n",
      "2.458350896835327\n",
      "2.4580893516540527\n",
      "2.457855463027954\n",
      "2.4576449394226074\n",
      "2.4574544429779053\n",
      "2.4572811126708984\n",
      "2.4571237564086914\n"
     ]
    }
   ],
   "source": [
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2025)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "lr = 50 # learning rate\n",
    "\n",
    "# gradient descent\n",
    "for k in range(500):\n",
    "    # forward pass\n",
    "    counts = W.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[xs, ys].log().mean()\n",
    "    if not (k % 20):\n",
    "        print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "  \n",
    "    # update\n",
    "    W.data += -lr * W.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add regularization term\n",
    "$$loss = -\\sum{\\log{W_{ij}}} + \\lambda\\cdot\\lVert W \\lVert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.786322832107544\n",
      "2.581151008605957\n",
      "2.5258102416992188\n",
      "2.5060460567474365\n",
      "2.4964168071746826\n",
      "2.491149663925171\n",
      "2.4880118370056152\n",
      "2.486006021499634\n",
      "2.4846532344818115\n",
      "2.4837069511413574\n",
      "2.4830262660980225\n",
      "2.4825243949890137\n",
      "2.4821462631225586\n",
      "2.4818546772003174\n",
      "2.4816250801086426\n",
      "2.481440782546997\n",
      "2.4812917709350586\n",
      "2.481168746948242\n",
      "2.481066942214966\n",
      "2.4809813499450684\n",
      "2.4809091091156006\n",
      "2.4808478355407715\n",
      "2.4807956218719482\n",
      "2.480750799179077\n",
      "2.4807119369506836\n"
     ]
    }
   ],
   "source": [
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2025)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "lr = 50\n",
    "lambda_ = 0.01\n",
    "\n",
    "# gradient descent\n",
    "for k in range(500):\n",
    "    # forward pass\n",
    "    counts = W.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[xs, ys].log().mean() + lambda_ * (W**2).mean()\n",
    "    if not (k % 20):\n",
    "        print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "  \n",
    "    # update\n",
    "    W.data += -lr * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previously, smaple from Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visthlynnnn.\n",
      "draclalelaika.\n",
      "deelax.\n",
      "ka.\n",
      "ereien.\n",
      "derbinnonos.\n",
      "shycleria.\n",
      "lahamanabor.\n",
      "jentrwairtiti.\n",
      "ssha.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2025)\n",
    "for i in range(10):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, smaple from the trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visthlynnnn.\n",
      "draclalelaika.\n",
      "deelaxwn.\n",
      "bereien.\n",
      "derbinnonosde.\n",
      "kileria.\n",
      "lahamanabor.\n",
      "jenarwairtiti.\n",
      "ssha.\n",
      "joviandarielam.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "counts = W.exp()\n",
    "p_net = counts / counts.sum(1, keepdims=True)\n",
    "g = torch.Generator().manual_seed(2025)\n",
    "for i in range(10):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = p_net[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
